{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "affe quickstart guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code-formatter, you cann comment it without losing functionality\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import affe\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affe.execs import (\n",
    "    CompositeExecutor,\n",
    "    NativeExecutor,\n",
    "    JoblibExecutor,\n",
    "    GNUParallelExecutor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affe import Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affe.tests import get_dummy_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Illustration: Flows saying _\"hi\"_\n",
    "\n",
    "To illustrate, let us create 10 different workflows. Each of those says \"hi\" in a signature way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a flow is very easy.\n",
    "flows = [\n",
    "    get_dummy_flow(message=\"hi\" * (i + 1), content=dict(i=i * 10)) for i in range(3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = flows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'io': {'fs': {'root': '/Users/zissou/repos/affe',\n",
       "   'cli': 'root',\n",
       "   'data': 'root',\n",
       "   'out': 'root',\n",
       "   'scripts': 'root',\n",
       "   'out.flow.config': 'out.flow',\n",
       "   'out.flow.logs': 'out.flow',\n",
       "   'out.flow.results': 'out.flow',\n",
       "   'out.flow.models': 'out.flow',\n",
       "   'out.flow.timings': 'out.flow',\n",
       "   'out.flow.tmp': 'out.flow',\n",
       "   'out.flow.flows': 'out.flow',\n",
       "   'out.flow': 'out'}},\n",
       " 'message': 'hi',\n",
       " 'content': {'i': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Execution\n",
    "\n",
    "Now you can print some hello worlds, embedded in a Flow object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "2 secs passed\n",
      "hi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/zissou/repos/affe/out/flow/logs/logfilehihi'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow.run()\n",
    "flow.run_with_log()\n",
    "\n",
    "flows[1].run_with_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Scheduling\n",
    "\n",
    "= Execution of multiple flows, for instance via a tool like `joblib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'i': 0}, {'i': 10}, {'i': 20}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = NativeExecutor\n",
    "c_jl = JoblibExecutor(flows, e, n_jobs=3)\n",
    "\n",
    "c_jl.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Creation of Flows\n",
    "\n",
    "The \"hi\"-flows defined above were nice because they illustrate in the simplest way possible what a flow is and how it can be used. In this section, we dive in a bit deeper in how you can make a Flow yourself, from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your workflow\n",
    "\n",
    "Typicall, you start from a certain workflow. As illustrated above, a _workflow_ is a piece of work you care about, and you want to be able to execute it in a controlled, experiment-like fashion. \n",
    "\n",
    "Here, we assume you are interested in the archetype machine learning task of predicting the specifies of the Iris flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Fit classifier\n",
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred, normalize=True)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make your _workflow_ into a _Flow_\n",
    "\n",
    "Now that you what you want to do, you want obtain a flow that implements this. The advantage is that annoying things like\n",
    "\n",
    "- logging\n",
    "- timeouts\n",
    "- execution\n",
    "- scheduling\n",
    "\n",
    "are all taken care of, as soon as you succeed. This means removing boilerplate, and using battle-tested code instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Basic Example (passing a function as argument)\n",
    "\n",
    "In its most basic form, this is a really simple thing, as we can just throw in a random python function _directly_. Consider this the _lazy_ way of doing things, which is supported.\n",
    "\n",
    "The only assumption is that your `flow` function has one input, typically named `config`. For the time being, this is a fairly constant assumption across `affe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello_world(config):\n",
    "    print(\"Hello World\")\n",
    "    return\n",
    "\n",
    "\n",
    "f = Flow(flow=hello_world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's nice and all, this is quick and dirty and it fails when you are trying to run this through a more advanced executor, such as one with logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logfile'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.run_with_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check the logfile, you can get some information as to why this is happening. Essentially, a common problem with abstracted execution is that you do need to have some kind of persistence of the code you wish to run. This is just to motivate that at times, you would want to build your custom subclass `Flow` object, which will not be plagued by such limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Flow as a Flow-Subclass\n",
    "\n",
    "This, we could consider the right way to do things in `affe`\n",
    "\n",
    "- Subclass the Flow class\n",
    "- Add anything you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implementation in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affe import Flow\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisFlow(Flow):\n",
    "    def __init__(self, max_depth=None, sleep_seconds=0, **kwargs):\n",
    "        \"\"\"\n",
    "        All the information you want to pass inside the flow function,\n",
    "        you can embed in the config dictionary.\n",
    "        \"\"\"\n",
    "        self.config = dict(max_depth=max_depth, sleep_seconds=sleep_seconds)\n",
    "        super().__init__(config=self.config, **kwargs)\n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def imports():\n",
    "        \"\"\"For remote executions, you better specify your imports explicitly.\n",
    "\n",
    "        Depending on the use-case, this is not necessary, but it will never hurt.\n",
    "        \"\"\"\n",
    "        from sklearn import datasets\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from time import sleep\n",
    "\n",
    "        return\n",
    "\n",
    "    def flow(self, config):\n",
    "        \"\"\"\n",
    "        This function is basically a verbatim copy of your workflow above.\n",
    "\n",
    "        Prerequisites:\n",
    "            - This function has to be called flow\n",
    "            - It expects one input: config\n",
    "\n",
    "        The only design pattern to take into account is that you can assume one\n",
    "        input only, which then by definition constitutes your \"configuration\" for your workflow.\n",
    "        Whatever parameters you need, you can extract from this. This pattern is somewhat restricitive,\n",
    "        but if you are implementing experiments, you probably should be this strict anyway; you're welcome.\n",
    "\n",
    "        The other thing is the name of this function: it has to be \"flow\", in order for some of the\n",
    "        executioners to properly find it. Obviously, if your only usecase is to run the flow function\n",
    "        yourself, this does not matter at all. But in most cases it does, and again: adhering to this pattern\n",
    "        will never hurt you, deviation could.\n",
    "        \"\"\"\n",
    "        # Obtain configuration\n",
    "        max_depth = config.get(\"max_depth\", None)\n",
    "        sleep_seconds = config.get(\"sleep_seconds\", 0)\n",
    "\n",
    "        print(\"I am about to execute the IRIS FLOW\")\n",
    "        print(\"BUT FIRST: I shall sleep {} seconds\".format(sleep_seconds))\n",
    "        sleep(sleep_seconds)\n",
    "        print(\"I WOKE UP, gonna do my stuff now.\")\n",
    "\n",
    "        # Load data\n",
    "        X, y = datasets.load_iris(return_X_y=True)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42\n",
    "        )\n",
    "\n",
    "        # Fit classifier\n",
    "        clf = DecisionTreeClassifier(max_depth=max_depth)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and Evaluate\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        score = accuracy_score(y_test, y_pred, normalize=True)\n",
    "\n",
    "        msg = \"\"\"\n",
    "        I am DONE executing the IRIS FLOW\n",
    "        \"\"\"\n",
    "        print(msg)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tryout\n",
    "\n",
    "Now, we can verify how this thing works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am about to execute the IRIS FLOW\n",
      "BUT FIRST: I shall sleep 0 seconds\n",
      "I WOKE UP, gonna do my stuff now.\n",
      "\n",
      "        I am DONE executing the IRIS FLOW\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7111111111111111"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_flow_02 = IrisFlow(max_depth=1)\n",
    "iris_flow_02.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am about to execute the IRIS FLOW\n",
      "BUT FIRST: I shall sleep 0 seconds\n",
      "I WOKE UP, gonna do my stuff now.\n",
      "\n",
      "        I am DONE executing the IRIS FLOW\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_flow_10 = IrisFlow(max_depth=10)\n",
    "iris_flow_10.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation in Codebase\n",
    "\n",
    "Alright, that looked pretty nice already. Now the question is: _what is in it for me?_\n",
    "    \n",
    "Well you get:\n",
    "- logging\n",
    "- timeouts\n",
    "- boilerplate filesystem managment\n",
    "- fancy executioners\n",
    "- and so much more!\n",
    "\n",
    "    \n",
    "So let's dive into that.\n",
    "\n",
    "However, the `IrisFlow` object does not exist outside of our Jupyter notebook, and that is unfortunately not OK for `affe` when running something in a subprocess/another shell, which is what you need to get these fancy functionalities.\n",
    "\n",
    "But, allow us to resume via a demonstration flow, which learns a decision tree on the iris dataset (yes, exactly what we were doing with our IrisFlow already). You can check the source code to verify that this does exactly the same thing as the IrisFlow above, with then the added feature that `IrisDemo` actually exists in your python path etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import\n",
    "\n",
    "Let us import the `IrisDemo` object, and demonstrate that it behaves exactly similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am about to execute the IRIS FLOW\n",
      "BUT FIRST: I shall sleep 0 seconds\n",
      "I WOKE UP, gonna do my stuff now.\n",
      "\n",
      "        I am DONE executing the IRIS FLOW\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from affe.demo import IrisDemo\n",
    "\n",
    "demoflow = IrisDemo(max_depth=3, log_filepath=\"logs/irisdemo\")\n",
    "demoflow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Logging\n",
    "\n",
    "Depending how you run the flow, another executioner is called in the backend. And some of those executors actually give you logging outside of the box, if you do it right.\n",
    "\n",
    "In our case, we need this one:\n",
    "- `DTAIExperimenterProcessExecutor` which is used in the `run_with_log_via_shell` function\n",
    "\n",
    "Additionally, if we specify the logfile parameter, we can give the logfiles custom names etc, which allows us to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/irisdemo'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demoflow = IrisDemo(max_depth=3, log_filepath=\"logs/irisdemo\")\n",
    "demoflow.run_with_log_via_shell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Timeouts\n",
    "\n",
    "To see how the timeouts work, we can use the \"sleep\" functionality to enforce our iris flow to take a bit longer. \n",
    "\n",
    "If force the workflow (due to sleeping) to take longer than the timeout, execution will abort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am about to execute the IRIS FLOW\n",
      "BUT FIRST: I shall sleep 5 seconds\n",
      "I WOKE UP, gonna do my stuff now.\n",
      "\n",
      "        I am DONE executing the IRIS FLOW\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will just work, because the run() method has no notion of timeout\n",
    "\n",
    "iris_flow = IrisDemo(\n",
    "    max_depth=10, sleep_seconds=5, log_filepath=\"logs/via-subprocess\", timeout_s=3\n",
    ")\n",
    "iris_flow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case, nothing really happens. Things change, however, when executing through shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/timeout-sufficient'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timeout is higher than the actual execution time\n",
    "\n",
    "iris_flow = IrisDemo(\n",
    "    max_depth=10, sleep_seconds=2, log_filepath=\"logs/timeout-sufficient\", timeout_s=10\n",
    ")\n",
    "iris_flow.run_with_log_via_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/timeout-insufficient'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timeout lower than execution time\n",
    "\n",
    "iris_flow = IrisDemo(\n",
    "    max_depth=10,\n",
    "    sleep_seconds=15,\n",
    "    log_filepath=\"logs/timeout-insufficient\",\n",
    "    timeout_s=10,\n",
    ")\n",
    "iris_flow.run_with_log_via_shell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check those logfiles yourself, and see what happens. The second logfile will tell you that it aborted due to hitting its timelimit, as it should."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filesystem Management\n",
    "\n",
    "This is not _by default_ in a Flow object, in order to keep things clean. However, there exists another object, which is called `FlowOne`. This is still very much a bare-bones object: it is a subclass of Flow, with some minimal bookkeeping for a common experimental filesystem configuration baked in.\n",
    "\n",
    "In that way, it becomes a very nice starting point for future extensions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affe.flow import FlowOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello_world(config):\n",
    "    print(\"Hello World\")\n",
    "    return\n",
    "\n",
    "\n",
    "f = FlowOne(flow=hello_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/zissou/repos/affe')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.root_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-655667435e2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_with_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/affe/src/affe/flow/Flow.py\u001b[0m in \u001b[0;36mrun_with_log\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_with_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local_log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/affe/src/affe/execs/DTAIExperimenterExecutor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, workflow, log_filepath, timeout_s)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mtimeout_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     ):\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_flow_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/affe/src/affe/execs/DTAIExperimenterExecutor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, workflow, log_filepath, timeout_s, memory_mb)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDTAIExperimenterExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         self.log_filepath = self.set_log_filepath(\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mworkflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_filepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         )  # This really has to happen first.\n",
      "\u001b[0;32m~/repos/affe/src/affe/execs/DTAIExperimenterExecutor.py\u001b[0m in \u001b[0;36mset_log_filepath\u001b[0;34m(workflow, log_filepath)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_filepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f.run_with_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Deep-dive\" into the Executors\n",
    "\n",
    "One of `affe`'s key contributions is its strict separation between three related things: _definition_ of a workflow, _actual execution of a workflow_ and lastly _scheduling multiple workflows_. \n",
    "\n",
    "This may seem trivial at first, but actually is responsible for making `affe` work for real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "affe",
   "language": "python",
   "name": "affe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
